OpenRefine - Short version
- First developed for OLA Education Institute webinar in April 2019
- Based on Library Carpentry OR lesson
- Updated Nov 2021

(SLIDE 1)
Welcome
Timeframe - 1h30

(SLIDE 2)
Who I am

CONTENTS
- Introduction
	What is OpenRefine
	Where does it come from
	What makes it different
	Why use it
	How does it work
- The OpenRefine workflow
	- Import
	- Analyze
	- Cleanup
	- Export
- Resources
	Some pointers on how to go further
- Discussion and Q&A
	Answer any questions you might have - as I go along, pleae put any questions in the chat.
		I will try to answer as many as I can on the go, we'll address any remaining ones
		at the end!
	Discuss any real life data cleanup use cases you might have


(SLIDE 3)
FOLLOW ALONG

We have about 1.5 hours today, so this won't be a fully interactive session.
I will try to give you a taste of the app by showing a few operations
Not comprehensive but a good overview

If you want, you can follow along as I go
    Paste link to data set https://github.com/LibraryCarpentry/lc-open-refine/raw/gh-pages/data/doaj-article-sample.csv

Or try on your own after

Companion document if need to get back to after (feel free to edit, add your own notes)
Has my contact info and links to more details
This roughly follows the Library Carpentry OR lesson, link in the document, can use it for self-teaching
https://docs.google.com/document/d/1a_UTudOcKHd9Y5BDAz-_6Eb-1cD74xOxNokkCyCNaS8/edit?usp=sharing


Also all links in slides



(SLIDE 4)
INTRO

Used to be GoogleRefine, now maintained by team of independent OSS developers.

Pros re spreadsheets:
- handles larger files (100'000 rows OK, does not scale to several millions)
- supports variety of input/output formats (csv, tsv, excel, odt, json, xml, custom text...)
- powerful filters, search & replace (regular expressions, etc.)
- predictive algorithms for clustering
- facets approach - a bit like discovery layers
- full undo/redo history
	- mistakes are OK
	- set of operations can be applied to other files
- easy APIs integration
- open infrastructure, custom functions can be developed

Cons:
- less intuitive to install & run
- non transparent saved files


(SLIDE 5)
Reasons to use OpenRefine:
- EXPLORE data
	- e.g. how are values distributed
	- think of facets in library search tool
- NORMALIZE/CLEAN UP data
	- inconsistent date formats
	- typos, case mismatch, markup errors, e.g. London, london, London;, LONDOND, etc.
	- Split unstructured data into structured, e.g. address all in one field split into street, city, postal code...
	- Enrich data from an external source, e.g. Virtual International Authority File


(SLIDE 6)
OpenRefine Workflow
Typical steps when working with data in OpenRefine:
	- Import
	- Analyze
	- Cleanup
	- Export

We'll go through each today.




(Interactive)

HOW TO INSTALL AND RUN

Download from openrefine.org
	- Version 3.4.1
Requires JAVA
	- Oracle discontinuing support for free Java, but still available

Interface in browser (http://127.0.0.1:3333) but RUNNING LOCALLY - data NOT IN THE CLOUD.
There is also a (paid) cloud service based on OpenRefine: http://refinepro.com/


Should open browser window when launched. If not, navigate to http://127.0.0.1:3333
Internet Explorer is not supported. Use Chrome or Firefox.





IMPORT DATA & CREATE PROJECT                      -           FIRST STEP in workflow: IMPORT


You can also open previous project


Multiple ways to import data
	- Local file
	- URL
	- Database connection
	- Copy and paste...


Use "from URL" functionality - https://raw.githubusercontent.com/LibraryCarpentry/lc-open-refine/gh-pages/data/doaj-article-sample.csv

Upload into Open Refine
	- already way more options than when importing into Excel
	- check headers
	- remove rows if needed
	- check encoding

Very fast. Displays only the first rows, can be changed. This makes it faster.

Uncheck "treat dates as dates etc."








3. EXPLORE DATA: SORT, FILTER, FACETS, CLUSTER  - 2:15    -           SECOND STEP in workflow: ANALYZE

See how data is displayed. Similar to spreadsheet.
Not all rows (or records) are displayed -> preview, faster. Adjustable

All operations are accessed through drop-down menus in the relevant column. For things affecting all columns (e.g reordering them), use the "All" column.

SORT
Choose a column, sort
See new drop down menu
- Similar to Excel "filter sort" -> temporary (unlike general Excel sort)
- Can be made permanent.



FACETS
Facets are one of most used features. Similar to what you would find in modern OPACs.

Ex. Language -> Text Facet
- we see data is messy, we can sort it out later

Can be combined with other facets (e.g. Publisher)

Invert option

Export as list by clicking the "choice" link


Different types, e.g. facet by blank (on the DOI column)




FILTERS
Facets will do exact matches by default. Can also use Filters to look for particular pattern in a column.

Ex. Subjects -> Text Filter "pyran"

Supports regular expressions!

	A Regular Expression is a powerful way to define search patterns. With it you can for example search for numbers that are formatted like a postal code.
	I have put the link to a few tutorials on Regular Expressions in the companion document.


-> remember, only displays first results, check # of matching results


IMPORTANT
When filters are applied, operations only perform on matching rows.
Example Language -> Edit Cells -> Common transforms -> to lowercase

Reset All  and Remove All buttons




IF time permits (next section at 2:30)
Other types of facets, e.g.
- Numeric
- Timeline
	- This looks weird, we'll get back to it
- Customized 
	- Word facet - this breaks down text into words and counts the number of records each word appears in
		For example, filter by language-ES then Word facet by author
			-> rudimentary author facet, we'll see how to do this better
            --> click "change" to change the character used for splitting from space to |
            --> note that it says GREL - hint that there is a language to do more detailed operations, 
                we'll talk more about it later
	- Text length facet
		Can be used to quickly see the distribution of title lenghts (Title -> text length facet)
        Or can be used to check data, e.g. Language more than 2 characters
        









4. CLEANING UP DATA  - 2:30                      -                       THIRD STEP in workflow: CLEANUP


Let's get back to our language facet.
We can use facets to quickly do some cleanup.

Edit the English facet
	This *alters* the data
	Undo function - see temporary message on top
	Also Undo/Redo history




Now let's have a look at the Authors column. Authors are separated by |
If we want to start analyzing or editing this column, we need to separate the authors.

Authors -> Edit cells -> Split multi-valued cells

It works, but what happened to the rows?
	OR didn't just create new rows and loose the relationship between authors.
	Show as records instead of rows
		Notice that "rows" belonging to the same records are grouped together (See numbering)




CLUSTERING
Now, do you trust the Authors column to always display an author the same way?
Try doing a text filter on the Authors column and type "vakeel"
	-> A. Khan Vakeel and Vakeel A. Khan is the same person.


There are probably any number of permutation and short variations in that author column. Cleaning it up by hand will be fastidious, write a function (e.g. using RegExp) to catch all possible forms will be just as hard.
But OpenRefine has a very powerful option: clustering.

(remove the filter first)
Authors -> Edit cells -> Cluster and edit

This blows my mind, every time. It's using different types of algorithms, you can play with the options until you find the one that works best.
If you're interested in what this all means, check out the Clustering in Depth link I've put in the references.

As usual with OpenRefine, it starts with previewing data changes only. You can decide which one you want to merge.




If time permits (next section at 3:00)
TRANSFORMS

We have a bit of time, so let's look at Transforms more in detail. 


Let's look at the Title column and use Edit Cells -> Transform

    The window that opens now has a prompt on top, expecting expressions in a syntax called 
    GREL: General Refine Expression Language.

	    It's a little like the formulas in Excel but more powerful.

	    Also supports Python and Clojure.

	I won't go very deep into GREL for this short introduction, but will show a few functions.
    In the companion document I've linked to a few GREL reference documents
    
    For example value.toUppercase()
    
    Preview window -> you can see what you're doing before applying it to large dataset
    
        See History, Starred, Help tabs
        

You don't need to know GREL to use the most common ones. 
Actually the one we just used (toUppercase) can be applied through Common Transforms


Some examples of common transforms:

Facet by publisher, select Askhantala + Technocrats
	include option to select more than 1
Have a look at the title - all uppercase
Do a Transform...
	value.toTitleCase()



Look at the date column
	
	Try a timeline facet - looks weird because not recognized as times

	Use Edit Cells -> Common Transforms -> To Date

	Check the timeline facet again!

	Will still not guarantee it will work if inconsistent date formats are use, e.g. European style d/m/y vs North-American style m/d/y...
	If you are in a situation like this, you might need to use GREL to first normalize dates








UNDO/REDO
OpenRefine keeps a history of all operations that alter the data (not filtering, faceting, etc.). Multiple undo
Can easily travel back to earlier stage.

Can also export a series of operations to be "played back"


(short break if enough time - check for questions)





EXPORTING DATA - 3:00                     -                       LAST STEP in workflow: EXPORT

Say we are now happy with how we cleaned up our data. 
The typical workflow is loading data in a particular format, working on it, exporting it in the same format
so we can then load it where it came from (for example a digital repostory or your ILS).

Before we export, we need to make sure the data is in the same format.
Remember the Authors column?

Edit Cell -> Join multi-valued cells




Export menu

Most common is CSV, TSV or Excel format

Custom tabular allows to select which columns you want to export, etc.
    Look at Download -> could export to exotic formats if needed
    Look at Upload -> could export to a Google Spreadsheet (heritage of when this was a Google product)
    You can even save your export option set (in JSON)

Templating for more advanced output. Also for JSON output.



If time permits

What if you need to work on MARC files?

Use MarcEdit to convert to TSV (best for larger files) or JSON and load in OpenRefine

Different mindset with MARC files - instead of one record per row, there's one row per MARC tag.
Still pretty crude, subfields are mixed with Content
Also need to move the Indicators to the left, otherwise it breaks the output...

Blank line to separate records

Use facet to select all tags, e.g. 250


When exporting back to MarcEdit, choose TSV





If time permits
Going further
    
- Reconciliation

What is reconciliation:
Christina Harlow: Compare values in my dataset with values in an external dataset, if deemed a match, link and pull in external datapoint information


We didn't have time to go through it in this intro, but check references for examples.

Use cases:
	- Georgraphical locations
	- Subject headings
	- Author names
	...

	Multiple sources available, Wikidata enabled by default
	Other sources: https://reconciliation-api.github.io/testbench/
	and https://github.com/OpenRefine/OpenRefine/wiki/Reconcilable-Data-Sources


	If enough time, reconcile Publishers via VIAF - Virtual International Authority File
    
    		- Do a text facet on Publishers
    		- Select International Union of Crystallography

	
	OR reconcile Authors via ORCID (go back to before joining them, select a subset - e.g. Aurel Vlacu publisher

    
    Clicking on blue links brings you to VIAF/ORCID/Wikidata page, can check if it's the right one.
    
    One tick: accept for this record only
    Two ticks: accept for all identical values
    
    If you're confident, can also do ‘Reconcile->Actions->Match each cell to its best candidate’
    
    To extract VIAF ID or ORCID ID (it's hidden by default)
        - Add column based on this column
        - GREL: cell.recon.match.id

    
    
- API calls

    See Add column by fetching URLs, for example on ISSN
    "https://api.crossref.org/journals/"+value
    
    If you want to run this live, filter by a couple of records only
    See https://librarycarpentry.org/lc-open-refine/13-looking-up-data/index.html for more details
    
    Returns as JSON, needs to be parsed first.




Last 15 minutes -- 3:15

WRAP UP

Anyone has an example of a dataset they'd like to use OpenRefine on?
Discussion of use cases


Point to companion document again

Mention that they can get back to me anytime

Resources - check out tutorials

