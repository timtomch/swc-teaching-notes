OpenRefine
- Based on Library Carpentry OR lesson

Used to be GoogleRefine, now maintained by team of independent OSS developers. Stable version is still called Google Refine, beta since 2013, relatively stable.

Interface in browser (http://127.0.0.1:3333) but RUNNING LOCALLY - data NOT IN THE CLOUD.
There is also a (paid) cloud service based on OpenRefine: http://refinepro.com/

Pros re spreadsheets:
- handles larger files (100'000 rows OK, does not scale to several millions)
- supports variety of input/output formats (csv, tsv, excel, odt, json, xml, custom text...)
- powerful filters, search & replace (regular expressions, etc.)
- predictive algorithms for clustering
- facets approach - a bit like discovery layers
- full undo/redo history
	- mistakes are OK
	- set of operations can be applied to other files
- easy APIs integration
- open infrastructure, custom functions can be developed

Cons:
- less intuitive to install & run
- non transparent saved files
- not much documentation
- development activity?


Reasons to use OpenRefine:
- EXPLORE data
	- e.g. how are values distributed
	- think of facets in library search tool
- NORMALIZE/CLEAN UP data
	- inconsistent date formats
	- typos, case mismatch, markup errors, e.g. London, london, London;, LONDOND, etc.
	- Split unstructured data into structured, see online example
	- Enrich data from an external source, e.g. Virtual International Authority File


CONTENTS
- Creating a project & importing data
- Exploring data through filtering, faceting and clustering
- Cleaning up data: split, merge, remove whitespaces, etc.
- Use GREL to perform more complex operations
- Save and reuse workflows
- Reconciliation and APIs
- Exporting data





1. HOW TO INSTALL AND RUN

Download from openrefine.org
	- Google Refine 2.5 STABLE
	- Open Refine 2.6 BETA
Requires JAVA.

Should open browser window when launched. If not, navigate to http://127.0.0.1:3333
Internet Explorer is not supported. Use Chrome or Firefox.


2. IMPORT DATA & CREATE PROJECT

Download sample file from bit.ly/openrefine
OR
Use "from URL" functionality - http:// has to be specified

Upload into Open Refine
	- check headers
	- remove rows if needed
	- check encoding

Very fast. Displays only the first rows, can be changed. This makes it faster.

Reorder columns, hide, etc.

ACTIVITY:
- Play around with import options. Encoding. Live preview.
ADVANCED:
- Try out importing XML or JSON data - record path

Please uncheck "treat dates as dates etc."
Once you're finished, create project.


3. EXPLORE DATA: SORT, FILTER, FACETS, CLUSTER
See how data is displayed. Similar to spreadsheet.
Not all rows (or records) are displayed -> preview, faster. Adjustable

RE-ORDER
All->Edit columns->Reorder or Remove
Drag and drop

SORT
Choose a column, sort
See new drop down menu
- Similar to Excel "filter sort" -> temporary (unlike general Excel sort)
- Can be made permanent.
Add more columns

FACETS
Facets are one of most used features. Similar to what you would find in modern OPACs.

Ex. Language -> Text Facet
- we see data is messy, we can sort it out later


ACTIVITY:
- Which licences are used for articles in this file? Which is the one used the msot? How many articles for each license?
- Can you isolate articles for which no license has been assigned?
- Try creating other facets and combining.

- What happens if you try to create a timeline facet with the dates?

Facets will do exact matches by default. Can also use Filters to look for particular pattern in a column.

Ex. Subjects -> Text Filter "pyran"

Supports regular expressions!

-> remember, only displays first results, check # of matching results

IMPORTANT
When filters are applied, operations only perform on matching rows.
Example Language -> to lowercase


Other types of facets, e.g.
- Numeric
- Timeline
- Customized 
	- Word facet - this breaks down text into words and counts the number of records each word appears in
		For example, filter by language-English then Word facet by author
			-> rudimentary author facet, we'll see how to do this better
	- Text length facet
		Can be used to check data, e.g. Language more than 2 characters

4. CLUSTERING

We could work on solving all those problems one by one, or with regular expressions. But there's a faster approach with clustering.

Date of Publication -> Text facet -> Cluster

OpenRefine will apply algorithm to try and group expressions together. Try different algos & parameters to check.
Once happy, hit select all (or only select those who make sense) & apply

Not perfect, but a start. Can then work on remaining ones.

5. TRANSFORMATIONS

Clear the cluster facet.

Apply blank facet to Date of Publication, filter by blank ones. What's going on here?
Look at Place of Publication

Let's try extracting the date of publication from there.

Date of Publication -> Transform

GREL - General Refine Expression Language
(see help tab)

Can refine cells from other columns, e.g. cells["Place of Publication"].value

Combine with other functions. Date is after a , try splitting with comma:

smartSplit(cells["Place of Publication"].value,",")[1]

6. UNDO/REDO
(if not shown earlier)

Can revert to previous state
Can save operations as JSON, and apply to other file

--> single cell operations are not exported

7. API integration

How can we enrich our data? Say we want to get autor IDs from VIAF (Virtual International Authority File)

First, let's filter a manageable part of the data, using date of publication, text filter, choose a year with about 10 results, e.g. 1808.

Select Add column based on URL

Name VIAF JSON
Expression: "http://viaf.org/viaf/AutoSuggest?query="+ escape(value,'url')
Check delay to not overwhelm server

we see that some will have returned data

To extract VIAFID

Text transform, enter forEach(value.parseJson().result, v, v.viafid)

8. RECONCILIATION

What is reconciliation:
Christina Harlow: Compare values in my dataset with values in an external dataset, if deemed a match, link and pull in external datapoint information

Reconciliation functions
Even easier, people have implemented database interfaces that interact directly with OpenRefine.
Of interest to librarians:
- VIAF
- LCSH
- JournalTOCs
- FundRef (e.g. to link publications to funding source)
- FAST (Faceted Application of Subject Terminology)

(freebase is phasing out)

Add standard service: http://iphylo.org/~rpage/phyloinformatics/services/reconciliation_viaf.php


8. EXPORT

Demonstrate variety of export formats.

JSON via templating, can also be used to export e.g. HTML table or Markdown, or Wikipedia format, etc.

Custom Tabular Exporter
	- several options
	- download locally
	- upload to Google Spreadsheet or Google Fusion table

Google Fusion example
- First filter by year to limit number of lines, e.g. 1852
- Custom Tabular Exporter, limit columns but be sure to include place of publication
- Upload to Google Fusion table
- Go to https://drive.google.com/drive/recent open created table
- Change Place of Publication type from text to location
- Add map tab


Resources:
- http://www.meanboyfriend.com/overdue_ideas/2014/11/working-with-data-using-openrefine/
- NCompass Live, Using MarcEdit & Open Refine: http://nlc.nebraska.gov/scripts/calendar/eventshow.asp?ProgID=14290
- http://enipedia.tudelft.nl/wiki/OpenRefine_Tutorial
- GoogleRefine tutorials (YouTube)
- OpenRefine book
- https://github.com/OpenRefine/OpenRefine/wiki/Reconcilable-Data-Sources#librarians
- http://www.datacarpentry.org/OpenRefine-ecology-lesson/00-getting-started.html
- https://github.com/LODLAM/LODLAMTO16/tree/master/OpenRefine_Tutorial using the RDF extension. This tutorial requires some advanced knowledge of RDF/LOD. Also LODRefine and the RDF extension are no longer supported, very finicky re: Java version, etc. Not sure this is a good example for begninners.

Install help & troubleshooting:
- https://groups.google.com/forum/#!forum/openrefine
- https://summit.uwaterloo.ca/p389l6kkluv/ (webinar)